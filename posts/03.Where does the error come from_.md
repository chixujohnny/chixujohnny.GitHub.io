# 03.Where does the error come from?

这一部分我们讨论的是，这个error究竟来自什么地方。<br />
<br />error来自于两个部分：

- **bias（偏差）**
- **variance（方差）**

**<br />其实了解error来源还是蛮重要的，因为一般训练一个model就看一下error rate这样子，毫无整改的头绪，效率很低。但如果你能精确的诊断出你的error来自于哪里，你就可以挑选适当的方法来提升你的model。

# Estimator


假设还是给定宝可梦特征预测宝可梦进化后cp值的问题，此时只有游戏开发公司知道这个$$\hat f$$，我们通过训练数据训练出来一个 $$f^*$$，实际上这个$$f^*$$是 $$\hat f$$ 的estimator（估计），我们的目标肯定是希望$$f^*$$越像$$\hat f$$越好。

打个比方，如下图，就好像$$\hat f$$是靶纸的中心，$$f^*$$是我们用训练数据训练出的function，它距离中心会有一个距离，那么这个距离的产生可能是bias造成的，也有可能是variance造成的。<br />![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585191251929-fcaa09f5-642e-4b0c-8c1e-45f721d4732b.png#align=left&display=inline&height=327&name=image.png&originHeight=1072&originWidth=1148&size=1004073&status=done&style=none&width=350)

下面形象的解释一下：<br />假设有一组变量$$x$$，我要估测它的mean该怎么做：

- 假设 $$x$$ 的mean是 $$\mu
$$ ，它的variance是 $$\sigma^2$$
- 估测mean的话就先抽样$$N$$个点$$\{x^1,x^2,\ldots,x^N\}$$<br />我们再把这$$N$$个点算一个平均值 $$m=\frac{1}{N} \sum_{n} x^n \ne \mu$$ 很显然，如果我们不取无穷多个点，这个$$m$$跟$$\mu$$是不相等的。但是如果你计算$$m$$的期望值 $$E[m]=E[\frac{1}{n}\sum_{n} x^n]=\frac{1}{N}\sum_{n} E[x^n]=\mu$$ 那么得到的值就是 $$\mu$$。<br />可以理解为你要打靶的目标是 $$\mu$$ 但是由于机械故障，你打到的 $$m$$ 散落在它的周围。这个估计是unbiased
- 那散布在周围散布的有多开呢，就取决于variance $$Var[m]=\frac{\sigma^2}{N}$$ ，这个variance取决你取了多少个样本。<br />如果 $$N$$ 比较小，就会像下面左图这样分散的比较开；反之就会像右图那样：                                      

                                                    ![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585208967064-3a1f214c-2703-4850-8cae-2327a5a5b188.png#align=left&display=inline&height=146&name=image.png&originHeight=962&originWidth=304&size=87017&status=done&style=none&width=46)                       ![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585209023676-64935b9c-bd84-410c-8c42-72e8f523f7c7.png#align=left&display=inline&height=147&name=image.png&originHeight=968&originWidth=310&size=95276&status=done&style=none&width=47)

- 估测variance的话还是先取 $$N$$ 个点$$\{x^1,x^2,\ldots,x^N\}$$，那么有：

                                  <br />                                          $$m=\frac{1}{N}\sum_{n} x^n$$  ，  $$s^2=\frac{1}{N}\sum_{n}(x^n-m)^2$$

    那么这个 $$s^2$$ 就可以来估测 $$\sigma^2$$，同样这一堆 $$s^2$$ 会散布在 $$\sigma^2$$ 的周围。但是这个估计是biased的，也就是说如 果取 $$s^2$$ 的期望值，那么不会等于 $$\sigma^2$$ 而是 $$\frac{N-1}{N}$$ 倍的 $$\sigma^2$$ 就是这个公式：$$E[s^2]=\frac{N-1}{N}\sigma^2 \ne \sigma^2$$，所以你会发现这一堆 $$s^2$$ 比 $$\sigma^2$$ 小的占多数，如下图（下图那堆$$s$$应该是带平方的）：<br />![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585209807884-0883db6a-c111-4a94-8b23-8f56165612b5.png#align=left&display=inline&height=232&name=image.png&originHeight=1148&originWidth=322&size=164812&status=done&style=none&width=65)<br />    如果 $$N
$$ 比较大的话，那么 $$E[s^2]$$ 跟 $$\frac{N-1}{N}\sigma^2$$ 的差距就会变小。

**下面再回到Regression这个问题：**<br />![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585210168435-e53cda47-9106-4f58-886c-37294da7d549.png#align=left&display=inline&height=154&name=image.png&originHeight=798&originWidth=1034&size=684134&status=done&style=none&width=200)

现在我们要估测的是靶的中心，也就是 $$\hat{f}$$ ，这个是我们的目标，通过你收集一些数据训练出的 $$f^*$$ 可能在上面那个位置，$$f^*$$跟红心之间的error其实有两件事：

1. 你瞄准的位置在哪里，即你这个estimator是不是biased。怎么知道estimator是不是biased的呢，假设你可以做很多次实验，就可以计算$$f^*$$的期望值$$E[f^*]= \overline{f}$$，这个$$\overline{f}$$就是平均值的意思，这个 $$\overline{f}$$ 跟靶心之间就有一段距离，也就是说，你在瞄的时候就没有瞄准。
1. 同时，$$f^*$$跟$$\overline{f}$$之间也有一些距离，这就表示了variance。

![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585210854299-7489234f-8d40-4ec7-ad4a-ccc88d07e7da.png#align=left&display=inline&height=196&name=image.png&originHeight=850&originWidth=1028&size=797635&status=done&style=none&width=237)<br />
<br />所以说造成的偏移是由bias跟variance共同造成的。<br />

## variance

<br />而我们在训练模型时，比较简单的模型，它的variance是比较小的，如下图：<br />![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585211254313-acdaee29-70c2-4c90-9b37-759853c338ce.png#align=left&display=inline&height=298&name=image.png&originHeight=1128&originWidth=1032&size=696728&status=done&style=none&width=273)<br />而我们用比较复杂的模型时，variance就很大，感觉就像打的靶子散的很开，如下图：<br />![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585211321290-1c46c4b3-a07d-48c7-89b4-2c52fcde72dd.png#align=left&display=inline&height=384&name=image.png&originHeight=1466&originWidth=1118&size=1723997&status=done&style=none&width=293)<br />**为什么简单的模型variance就比较小，反之就比较大呢？**<br />简单的model受到不同的样本影响是比较小的，而复杂的model受到不同的样本影响就很大。<br />

## bias

<br />bias：我们现在有很多很多的 $$f^*$$，假设我们现在把这堆 $$f^*$$ 平均起来找它的期望值$$E[f^*]=\overline{f}$$，也就是 $$\overline{f}$$ 的话，那么bias就是衡量 $$\overline{f}$$ 跟靶心 $$\hat{f}$$ 之间的距离。

下面左图是个比较简单的model，那么它就有一个比较大的bias，右图是一个很复杂的模型，它会有比较小的bias。<br />![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585294618750-e8f900ba-101a-49b1-9821-c125316ea089.png#align=left&display=inline&height=252&name=image.png&originHeight=850&originWidth=1152&size=510677&status=done&style=none&width=341)![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585294638270-5243bd4e-14e7-4ee7-bd56-7fc9b1b89157.png#align=left&display=inline&height=219&name=image.png&originHeight=720&originWidth=1114&size=635610&status=done&style=none&width=339)<br />                    ![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585294694407-f1112e00-3128-49ab-a1fa-b70df4f91585.png#align=left&display=inline&height=153&name=image.png&originHeight=492&originWidth=734&size=326844&status=done&style=none&width=229)                 ![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585294747907-3aba572f-d0ee-4b38-8a8b-f7f155983958.png#align=left&display=inline&height=148&name=image.png&originHeight=502&originWidth=812&size=391857&status=done&style=none&width=242) <br />
<br />**那么为什么会产生上图那样的结果呢？有一个比较直观的解释：**<br />model就是一个function set，我们可以用一个范围表示一个function set，当你定义一个model的时候，你就设定好你最好的funciton就只能从这个function set里面挑出来，如果是一个比较简单的model，那么这个function set的区域就会比较小，都不会包含靶心target，就像下图那样：<br />![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585296077436-ab73a75f-591d-4e07-ae0c-077b08937dcc.png#align=left&display=inline&height=171&name=image.png&originHeight=542&originWidth=1052&size=424773&status=done&style=none&width=332)<br />如果在没有包含target的情况下，你在这个蓝色圈圈里不管怎么sample，平均起来都不会是这个target的。

那么如果你的model比较复杂，那么这个function的space是比较大的，可能有包含这个靶心target，只是没有办法找出这个target在哪里，因为你给定的训练数据不够，每次得到的$$f^*$$都不一样，但是如果他们是散布在target附近的，那么平均起来就可以得到$$\overline{f}$$。

## 总结一下


- 如果你的model很简单，那么bias很大，但是variance比较小。
- 如果你的model非常复杂，就会有很小的bias但是variance会很大。
- 如果你的error大部分来自variance，那么这个叫做overfitting。
- 如果你的error大部分来自bias，那么这个叫做underfitting。



# 
# 如何诊断你的模型是bias大还是variance大？


- 如果你的model没有办法很好的拟合你的训练数据，那么就代表你的bias是大的。
- 如果你可以很好的拟合你的训练数据，在训练数据上得到很小的error，但是在测试数据上却有很大的error，这就证明你的model可能variance比较大。



## 如何解决？


- bias比较大：<br />增加更多的特征<br />让你的模型更复杂

- variance比较大：<br />增加训练数据/ 根据自己的经验创造更多的训练数据<br />Regularzation正则化：会调整你的function space，负面影响是可能增加bias
