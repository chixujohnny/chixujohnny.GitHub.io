# 05.Classification: Probabilistic Generative Model



# 分类问题

<br />下面我们要进入的是**分类**这件事情。<br />
<br />如果是二分类问题的话，依旧按照之前讲的3个step去建模：

- 寻找一个Function(Model)<br />这个$$f(x)$$可以表示为：我们通过训练数据训练一个$$g(x)$$，如果$$g(x)>0$$，输出$$class=1
$$，否则输出$$class=2$$

-  定义Loss<br />如果我们选了一个function $$f$$，它在我们训练数据上面预测错误次数越少，表示这个Loss越小。

                                            $$L(f)=\sum_{n} \delta(f(x^n) \ne \hat y^n)$$

- 但是这个是离散的，没有办法做微分啊，我们有一些方法去解，比如：Perceptron、SVM。但是现在不讲这两个，我们先用几率的观点来看待它，然后会解释这其实跟ML的3个step是一样的。


<br />

# 概率问题回顾

<br />假设现在有两个盒子，里面有不同数目的蓝球和绿球，如下图：<br />![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585882465567-f4672858-28f8-4e19-9478-1d7435691b22.png#align=left&display=inline&height=282&name=image.png&originHeight=564&originWidth=1984&size=415933&status=done&style=none&width=992)<br />
<br />那么得到一个蓝球，它从Box1中抽出的几率就是：<br />
<br />$$P(B_1|Blue)=\frac{P(Blue|B_1)P(B_1)}{P(Blue|B_1)P(B_1)+P(Blue|B_2)P(B_2)}$$<br />
<br />现在我们把Box换成Class的话就是：<br />![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1585882744555-a91f11ad-714e-41fc-8d2d-a599f7e3725b.png#align=left&display=inline&height=287&name=image.png&originHeight=574&originWidth=2040&size=420073&status=done&style=none&width=1020)<br />
<br />那么我们从Class1中抽出一个$$x$$的几率是多少呢？

$$P(C_1|x)=\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}$$<br />
<br />如果我们分别知道知道几率$$P(C_1|x)$$和$$P(C_2|x)$$的话，那么只要选一个几率大的就可以知道这个$$x$$属于哪个class了。

但现在的问题是，如果我们要算$$P(C_1|x)$$或$$P(C_2|x)$$的话，就要计算下面这四个值：

- $$P(C_1)$$：在Class1中抽到的概率。
- $$P(x|C_1)$$：$$x$$在Class1中被抽到的几率。
- $$P(C_2)$$：在Class2中抽到的几率。
- $$P(x|C_2)$$：$$x$$在Class2中被抽到的几率。



这四个值需要我们从我们的训练数据中估测出来。**这种思想叫做Generative Model，为什么这么叫呢？因为你可以拿它来Generate一个$$x$$，你可以计算某一个$$x$$****出现的几率$$P(x)$$，如果你可以计算每一个$$x$$出现的几率，你就知道了$$x$$的分布，你就可以用这个分布来产生$$x$$。这个几率$$P(x)$$很简单：**<br />**<br />**$$P(x)=P(x|C_1)P(C_1)+P(x|C_2)P(C_2)$$**<br />**<br />举个例子，假如说我们现在有79只水系宝可梦的特征分布，如果新来了一只没见过的“海龟”想要知道它是水系宝可梦的概率。那么我们假设这79个点是从一个高斯分布中抽样出来的，下面的问题就变成了，如果给我这79个点，怎么从中找出那个高斯分布。
# Gaussian Distribution

<br />假设你不知道高斯分布是什么的话，就可以把它想象成一个function，这个function的输入就是一个向量$$x$$表示这只宝可梦的特征分布，输出这只宝可梦从这个分布中被抽样出来的几率，严格意义上来讲，这个并不算是几率，而是probability density（概率密度），它跟几率是成正比的，但它并不完全等于几率。

这个几率分布是由两个东西来决定的，一个是均值$$\mu$$它是一个vector，一个是协方差$$\sigma$$它是一个matrix，同样的$$x$$带入下面的公式中，如果有不同的$$\mu$$跟$$\sigma$$那么它输出的几率分布就会是不一样的：

$$f_{\mu,\sigma}(x)=\frac{1}{(2\pi)^{D/2}}\frac{1}{|\sigma|^{1/2}}exp\{-\frac{1}{2}(x-\mu)^T\sigma^{-1}(x-\mu)\}$$

下面的问题就是，怎么找$$\mu$$和$$\sigma$$，这里面用到的概念叫做Maximum Likelihood（极大似然）

## Maximum Likelihood


你可以想象成，这79个点可以从任何一个高斯分布中被抽样出来，任何一个高斯分布都可以抽样出这79个点，但是这堆高斯分布抽出这79个点的likelihood（可能性）是不一样的。所以说如果今天给我们某个高斯分布的$$\mu$$和$$\sigma$$，我们就可以算这个高斯分布抽样这79个点的几率，这个Likelihood $$L$$（可能会跟Loss搞混，但是实在是找不到更好的符号表达了）我们可以写成下面这个式子，将$$\mu$$和$$\sigma$$带入这个Likelihood function里面，会输出这$$\mu$$和$$\sigma$$抽样出这79个点的几率有多大：

$$L(\mu,\sigma)=f_{\mu,\sigma}(x^1)f_{\mu,\sigma}(x^2)f_{\mu,\sigma}(x^3)......f_{\mu,\sigma}(x^{79})$$

$$f_{\mu,\sigma}(x^1)$$表示这个高斯分布抽出第1个点的几率<br />$$f_{\mu,\sigma}(x^2)$$表示这个高斯分布抽出第2个点的几率<br />......<br />$$f_{\mu,\sigma}(x^{79})$$表示这个高斯分布抽出第79个点的几率

我们下面要做的事情就是要找到这个高斯分布，这个likelihood最大的高斯分布我们写做$$(\mu^*,\sigma^*)$$

$$L(\mu,\sigma)=f_{\mu,\sigma}(x^1)f_{\mu,\sigma}(x^2)f_{\mu,\sigma}(x^3)......f_{\mu,\sigma}(x^{79})
$$<br />$$f_{\mu,\sigma}(x)=\frac{1}{(2\pi)^{D/2}}\frac{1}{|\sigma|^{1/2}}exp\{-\frac{1}{2}(x-\mu)^T\sigma^{-1}(x-\mu)\}$$<br />
<br />然后我们要穷举所有的$$\mu$$和$$\sigma$$，看哪一组可以让上面的Likelihood结果最大，那么就是我们要找的$$\mu^*,\sigma^*$$<br />
<br />$$\mu^*,\sigma^*=arg\max_{\mu,\sigma}L(\mu,\sigma)$$<br />
<br />我们就当做这79个点就从这$$\mu^*,\sigma^*$$中抽样出来的。

$$\mu^*=\frac{1}{79}\sum_{n=1}^{79}x^n$$

$$\mu^*$$算出来之后我们再算$$\sigma^*$$

$$\sigma^*=\frac{1}{79}\sum_{n-1}^{79} (x^n-\mu^*)(x^n-\mu^*)^T$$

上面那个$$T
$$表示transpose。

## 下面我们可以开始做分类问题了

<br />回顾一下上面，要做的分类问题我们只要算出下面这个公式就可以了，表示样本$$x$$属于类别$$C_{1}$$的几率：

$$P(C_1|x)=\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}$$<br />
<br />如果$$P(C_1|x)>0.5$$则样本$$x$$属于类别$$C_{1}$$，那么展开来的话，就是下面这个图：<br />![image.png](https://cdn.nlark.com/yuque/0/2020/png/1173836/1586240856315-d1699755-b083-4835-b3cb-6a2f79983308.png#align=left&display=inline&height=565&name=image.png&originHeight=1130&originWidth=2308&size=1025102&status=done&style=none&width=1154)

上图是仅使用了2个特征，所以$$\mu$$是一个2维向量，$$\sigma$$是一个2x2的矩阵。

# Three Steps


我们来回顾一下我们讲的几率模型，我们之前说机器学习就是3个step，那么几率模型其实也是三个step。

## Step1 - Model

<br />首先你有一个Model，这个Model就是一个Function Set，这个Function Set里面的Function都长下面这个样子：

$$P(C_1|x)=\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}$$<br />
<br />我们class-1出现的概率$$P(C_1)$$，class-2出现的概率$$P(C_2)$$，在class-1中出现$$x$$的概率分布$$P(x|C_1)$$，在class-2中出现$$x$$的概率分布$$P(x|C_2)$$，其中$$P(x|C_1)$$和$$P(x|C_2)$$是Model的参数，你选择不同的概率分布（也就是Guassian选择不同的mean和不同的covariance matrix），就得到不同的Function，你把这些不同的Funciton组合起来就成了一个Function Set也就是一个Model。

如果$$P(C_1|x)>0.5$$则样本$$x$$属于类别$$C_{1}$$，反之则属于$$C_{2}$$。

## Step2 - Goodness of a function

<br />在几率模型中，假设我们使用的是Guassian的话，那么我们衡量的对象就是Guassian里面的参数mean $$\mu$$ 和covariance matrix $$\sigma$$，我们要做的是寻找一组$$\mu$$和$$\sigma$$让likelihood最大化。

## Step3 - Find the best function


这部分简单，就不展开讲了。


---


<br />有人要问你为什么要用【高斯分布】这个几率模型，那么我假如用了别的分布你可能也会有同样的问题。**实际上你可以选一个你自己喜欢的Probability Distribution，你选择简单的几率模型参数比较少的那就会bias比较大variance比较小；你选择参数比较多的比较复杂的几率模型那就会bias比较小variance比较大。**
